{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fusion Optimis\u00e9e (Chunking + D\u00e9doublonnage)\n",
                "Ce script g\u00e8re les gros volumes de donn\u00e9es en :\n",
                "1. Chargeant et d\u00e9doublonnant le fichier DPE (ne garde que le DPE le plus r\u00e9cent par adresse).\n",
                "2. Lisant le fichier Conso par blocs (chunks) pour \u00e9viter de saturer la m\u00e9moire.\n",
                "3. Ecrivant le r\u00e9sultat au fur et \u00e0 mesure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "\n",
                "# Chemins des fichiers\n",
                "path_conso = r'c:\\Users\\elean\\OneDrive\\Bureau\\DPE\\conso_geocoded_brut.csv'\n",
                "path_dpe = r'c:\\Users\\elean\\OneDrive\\Bureau\\DPE\\dpe03existant.csv'\n",
                "path_output = r'c:\\Users\\elean\\OneDrive\\Bureau\\DPE\\fusion_dpe_conso.csv'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_dpe(path_dpe):\n",
                "    print(\"Chargement et pr\u00e9paration du fichier DPE...\")\n",
                "    # On s\u00e9lectionne les colonnes utiles si possible pour gagner de la m\u00e9moire\n",
                "    # Ici on charge tout mais on pourrait optimiser usecols\n",
                "    try:\n",
                "        df_dpe = pd.read_csv(path_dpe, sep=',', low_memory=False)\n",
                "        \n",
                "        original_len = len(df_dpe)\n",
                "        print(f\"DPE charg\u00e9 : {original_len} lignes\")\n",
                "        \n",
                "        # V\u00e9rification de la colonne identifiant\n",
                "        if 'identifiant_ban' not in df_dpe.columns:\n",
                "            raise ValueError(\"Colonne 'identifiant_ban' manquante dans le fichier DPE\")\n",
                "            \n",
                "        # D\u00e9doublonnage : Garder le DPE le plus r\u00e9cent pour chaque identifiant_ban\n",
                "        # On suppose qu'il y a une colonne de date pour trier, sinon on garde le premier/dernier arbitrairement\n",
                "        if 'date_etablissement_dpe' in df_dpe.columns:\n",
                "            print(\"D\u00e9doublonnage bas\u00e9 sur la date d'\u00e9tablissement...\")\n",
                "            df_dpe['date_etablissement_dpe'] = pd.to_datetime(df_dpe['date_etablissement_dpe'], errors='coerce')\n",
                "            df_dpe = df_dpe.sort_values('date_etablissement_dpe', ascending=False)\n",
                "            \n",
                "        df_dpe = df_dpe.drop_duplicates(subset=['identifiant_ban'], keep='first')\n",
                "        print(f\"Apr\u00e8s d\u00e9doublonnage : {len(df_dpe)} lignes (Doublons supprim\u00e9s : {original_len - len(df_dpe)})\")\n",
                "        \n",
                "        return df_dpe\n",
                "    except Exception as e:\n",
                "        print(f\"Erreur traitement DPE: {e}\")\n",
                "        return None\n",
                "\n",
                "# Ex\u00e9cution du traitement DPE\n",
                "df_dpe_clean = process_dpe(path_dpe)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if df_dpe_clean is not None:\n",
                "    print(\"D\u00e9but du traitement par chunks du fichier Conso...\")\n",
                "    \n",
                "    chunksize = 100000  # Taille des blocs \u00e0 traiter\n",
                "    first_chunk = True\n",
                "    total_processed = 0\n",
                "    total_matches = 0\n",
                "    \n",
                "    try:\n",
                "        # Lecture du fichier Conso par blocs\n",
                "        with pd.read_csv(path_conso, sep=',', chunksize=chunksize, low_memory=False) as reader:\n",
                "            for i, chunk in enumerate(reader):\n",
                "                # Fusion avec le r\u00e9f\u00e9rentiel DPE propre\n",
                "                merged_chunk = pd.merge(\n",
                "                    chunk, \n",
                "                    df_dpe_clean, \n",
                "                    left_on='result_id', \n",
                "                    right_on='identifiant_ban', \n",
                "                    how='inner'\n",
                "                )\n",
                "                \n",
                "                matches = len(merged_chunk)\n",
                "                total_matches += matches\n",
                "                total_processed += len(chunk)\n",
                "                \n",
                "                # Ecriture dans le fichier de sortie\n",
                "                if matches > 0:\n",
                "                    mode = 'w' if first_chunk else 'a'\n",
                "                    header = first_chunk\n",
                "                    merged_chunk.to_csv(path_output, mode=mode, index=False, header=header)\n",
                "                    first_chunk = False\n",
                "                \n",
                "                print(f\"Chunk {i+1} trait\u00e9 : {len(chunk)} lignes lues -> {matches} correspondances trouv\u00e9es.\")\n",
                "                \n",
                "        print(f\"\\nTraitement termin\u00e9 !\")\n",
                "        print(f\"Total lignes lues Conso : {total_processed}\")\n",
                "        print(f\"Total correspondances sauvegard\u00e9es : {total_matches}\")\n",
                "        print(f\"Fichier disponible ici : {path_output}\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Erreur lors du traitement par chunks : {e}\")\n",
                "else:\n",
                "    print(\"Impossible de proc\u00e9der : le traitement DPE a \u00e9chou\u00e9.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "print(\"\\n--- Visualisation du fichier fusionn\u00e9 (Extrait) ---\")\n",
                "try:\n",
                "    if 'path_output' not in locals():\n",
                "        path_output = r'c:\\Users\\elean\\OneDrive\\Bureau\\DPE\\fusion_dpe_conso.csv'\n",
                "    \n",
                "    # On charge uniquement les 20 premi\u00e8res lignes pour visualiser sans tout charger\n",
                "    df_preview = pd.read_csv(path_output, nrows=20, low_memory=False)\n",
                "    print(f\"Aper\u00e7u des 5 premi\u00e8res lignes :\")\n",
                "    print(df_preview.head())\n",
                "    \n",
                "    print(f\"\\nInfos sur les colonnes :\")\n",
                "    print(df_preview.info())\n",
                "except Exception as e:\n",
                "    print(f\"Erreur \u00e0 l'affichage : {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}