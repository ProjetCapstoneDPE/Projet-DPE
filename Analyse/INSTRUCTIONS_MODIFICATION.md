# Modifications pour cr√©er des mod√®les XGBoost par tranche de surface

## 1. D√©finir les tranches de surface

Ajoutez une cellule apr√®s le chargement des donn√©es pour d√©finir les tranches :

```python
# D√©finition des tranches de surface
def categoriser_surface(surface):
    if pd.isna(surface):
        return None
    elif surface <= 50:
        return '0-50m¬≤'
    elif surface <= 100:
        return '50-100m¬≤'
    elif surface <= 150:
        return '100-150m¬≤'
    else:
        return '>150m¬≤'

# Application aux donn√©es
df['tranche_surface'] = df['surface_habitable_logement'].apply(categoriser_surface)

# Afficher la distribution
print(df['tranche_surface'].value_counts())
```

## 2. Nettoyage et pr√©paration des donn√©es par tranche

Ajoutez apr√®s l'analyse des colonnes :

```python
# Filtrer les lignes sans surface
df_clean = df[df['tranche_surface'].notna()].copy()

# Afficher les statistiques par tranche
for tranche in df_clean['tranche_surface'].unique():
    print(f"\n=== Tranche {tranche} ===")
    df_tranche = df_clean[df_clean['tranche_surface'] == tranche]
    print(f"Nombre de logements : {len(df_tranche)}")
    print(f"Surface moyenne : {df_tranche['surface_habitable_logement'].mean():.2f}m¬≤")
```

## 3. Fonction pour cr√©er un mod√®le XGBoost par tranche

```python
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import pickle

def creer_modele_xgboost_par_tranche(df, tranche, features, target='conso_5_usages_e_finale'):
    """
    Cr√©e et entra√Æne un mod√®le XGBoost pour une tranche de surface sp√©cifique
    
    Param√®tres:
    - df: DataFrame complet
    - tranche: nom de la tranche (ex: '50-100m¬≤')
    - features: liste des colonnes √† utiliser comme features
    - target: colonne cible (par d√©faut 'conso_5_usages_e_finale')
    
    Retourne:
    - model: mod√®le entra√Æn√©
    - metrics: dictionnaire des m√©triques
    - X_test, y_test: donn√©es de test
    """
    
    # Filtrer les donn√©es pour cette tranche
    df_tranche = df[df['tranche_surface'] == tranche].copy()
    
    print(f"\n{'='*60}")
    print(f"Entra√Ænement du mod√®le pour la tranche : {tranche}")
    print(f"{'='*60}")
    print(f"Nombre d'√©chantillons : {len(df_tranche)}")
    
    # V√©rifier qu'il y a assez de donn√©es
    if len(df_tranche) < 100:
        print(f"‚ö†Ô∏è Attention : seulement {len(df_tranche)} √©chantillons pour {tranche}")
        return None, None, None, None
    
    # Pr√©parer X et y
    X = df_tranche[features]
    y = df_tranche[target]
    
    # Supprimer les lignes avec des valeurs manquantes dans la cible
    mask = y.notna()
    X = X[mask]
    y = y[mask]
    
    # G√©rer les valeurs manquantes dans X (remplir avec la m√©diane)
    X = X.fillna(X.median())
    
    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Cr√©er le mod√®le XGBoost
    model = xgb.XGBRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=42,
        n_jobs=-1
    )
    
    # Entra√Ænement
    print("Entra√Ænement en cours...")
    model.fit(X_train, y_train)
    
    # Pr√©dictions
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # M√©triques
    metrics = {
        'tranche': tranche,
        'n_samples': len(df_tranche),
        'n_train': len(X_train),
        'n_test': len(X_test),
        'mae_train': mean_absolute_error(y_train, y_pred_train),
        'mae_test': mean_absolute_error(y_test, y_pred_test),
        'r2_train': r2_score(y_train, y_pred_train),
        'r2_test': r2_score(y_test, y_pred_test)
    }
    
    # Affichage des r√©sultats
    print(f"\nüìä R√©sultats :")
    print(f"  - MAE Train : {metrics['mae_train']:.2f}")
    print(f"  - MAE Test  : {metrics['mae_test']:.2f}")
    print(f"  - R¬≤ Train  : {metrics['r2_train']:.4f}")
    print(f"  - R¬≤ Test   : {metrics['r2_test']:.4f}")
    
    return model, metrics, X_test, y_test
```

## 4. Boucle pour cr√©er tous les mod√®les

```python
# D√©finir les features √† utiliser
# (√Ä adapter selon vos colonnes disponibles)
features = [
    'surface_habitable_logement',
    'annee_construction',
    'zone_climatique',
    'type_batiment',
    # ... ajoutez les features pertinentes
]

# Dictionnaires pour stocker les mod√®les et m√©triques
modeles = {}
metriques_globales = []

# Cr√©er un mod√®le pour chaque tranche
for tranche in df_clean['tranche_surface'].unique():
    model, metrics, X_test, y_test = creer_modele_xgboost_par_tranche(
        df_clean, 
        tranche, 
        features
    )
    
    if model is not None:
        modeles[tranche] = {
            'model': model,
            'X_test': X_test,
            'y_test': y_test
        }
        metriques_globales.append(metrics)
        
        # Sauvegarder le mod√®le
        filename = f'modele_xgboost_{tranche.replace("-", "_").replace(">", "plus_")}.pkl'
        with open(filename, 'wb') as f:
            pickle.dump(model, f)
        print(f"‚úì Mod√®le sauvegard√© : {filename}\n")

# Afficher un tableau r√©capitulatif
import pandas as pd
df_metriques = pd.DataFrame(metriques_globales)
print("\n" + "="*80)
print("R√âCAPITULATIF DES MOD√àLES PAR TRANCHE")
print("="*80)
print(df_metriques.to_string(index=False))
```

## 5. Visualisation des performances

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Graphique comparatif des performances
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# MAE par tranche
axes[0].bar(df_metriques['tranche'], df_metriques['mae_test'])
axes[0].set_title('MAE par tranche de surface')
axes[0].set_xlabel('Tranche de surface')
axes[0].set_ylabel('MAE (kWh/m¬≤/an)')
axes[0].tick_params(axis='x', rotation=45)

# R¬≤ par tranche
axes[1].bar(df_metriques['tranche'], df_metriques['r2_test'])
axes[1].set_title('R¬≤ par tranche de surface')
axes[1].set_xlabel('Tranche de surface')
axes[1].set_ylabel('R¬≤')
axes[1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()
```

## 6. Fonction de pr√©diction

```python
def predire_consommation(surface, autres_features, modeles):
    """
    Pr√©dit la consommation en s√©lectionnant le mod√®le appropri√© selon la surface
    """
    # D√©terminer la tranche
    tranche = categoriser_surface(surface)
    
    if tranche not in modeles:
        print(f"‚ùå Pas de mod√®le disponible pour la tranche {tranche}")
        return None
    
    # Pr√©diction avec le bon mod√®le
    model = modeles[tranche]['model']
    prediction = model.predict([autres_features])
    
    return prediction[0]
```

## Remarques importantes

1. **Ajuster les tranches** : Vous pouvez modifier les seuils selon la distribution de vos donn√©es
2. **S√©lection des features** : Choisissez les colonnes pertinentes et sans trop de valeurs manquantes
3. **Hyperparam√®tres** : Vous pouvez optimiser les param√®tres XGBoost avec GridSearchCV
4. **Gestion des valeurs manquantes** : Adaptez selon vos besoins (m√©diane, mode, suppression...)
5. **Encodage** : Les variables cat√©gorielles devront √™tre encod√©es (One-Hot ou Label Encoding)
